here I'll draft my ideas for EA forum post

## Mapping the Future
When I started working for Metaculus I was quite excited. Having read books like Superforecasting and How to Measure Anything as well as being part of EA community where crowd-forecasting was considered cool. I considered it to be great opportunity. 

Now after working at Metaculus for 2 years I have learned few things about crows-sourced forecasting and I'm significantly more excited about opportunities in the space than I was before. 

**How Metaculus Changed**

Note that when I started working I was the only active developer with Max W as a person who basically coded the whole platform supporting me during his nights and weekends. Then he joined for couple of months and left again to work for OpenAI.

Now we finally grew the team significantly and engineering team as well (starting December 2021) so we will be able to execute much better than before. 

**Crowd sourced forecasting**

When I talk about my work to people, they often imagine that we are creating forecasting models about specific things, such as weather or company sales. Fortunately no, we are in business of forecasting the future, period. Which seems much more exciting in a way. We develop generic platform that can be used for all kinds of problems. 

*How does it work?*

The idea is very simple. 
- We specify question with well-defined resolution criteria. 
- Allow people to input probabilities
- The resulting average is surprisingly accurate


*Why is this useful?*

Mainly because this simple approach allows us to get meaningful probabilities about messy future events. [Reality is often underpowered](https://forum.effectivealtruism.org/posts/jSPGFxLmzJTYSZTK3/reality-is-often-underpowered) and for many things we care about we lack sufficient data to make robust quantitative models. 

Weather forecasting is interesting example. Weather is result of complex and chaotic system with too many interacting parts for us to gasp. But we managed to develop reasonably good short-term models, because of clever techniques and a ton of data we are gathering all the time.

> Weather forecasts are better than they ever have been. According to the World Meteorological Organization (WMO), a 5-day weather forecast today is as reliable as a 2-day forecast was 20 years ago! This is because forecasters now use advanced technologies to gather weather data, along with the worldâ€™s most powerful computers. Together, the data and computers produce complex models that more accurately represent the conditions of the atmosphere. These models can be programmed to predict how the atmosphere and the weather will change. Despite these advances, weather forecasts are still often incorrect. Weather is extremely difficult to predict because it is a complex and chaotic system.

When we talk about risk of nuclear war, or dangers of new technologies our datasets are far far behind the weather datasets. We cannot do the same clever data analyses if we don't have the same data.

This might result in much simpler models, or more qualitative in nature. We can still express our probabilities and uncertainity. This is when aggregation comes in. If we take many of these simple models and create average out of them, the result is quite accurate. It's surprisingly hard to beat the average. 

Imagine doing Fermi estimations. Instead of trying to do final estimate such as "how many dogs there are in Prague?" you divide it into subproblems
- What is the population of Prague?
- How many people live on average in a home?
- What proportion of homes have a dog (or more)?

Then I can estimate each of the subproblems and my biases will go randomly into both directions, so my final estimate might be surprisingly good. This would work better with more subestimates. I might be also systematically biased to one direction for some questions, of course.

Forecast aggregation works similarly. People are biased in all kinds of ways, but average cancels it out. It does matter who is forecasting of course and how much effort they put into it. 

**Top Forecasters**

It's hard to be better than the average, but some people can do it. If we give more weight to these people we get what we call Metaculus Prediction (time and track record weighted average).

Identifiyng and rewarding top performers is important part of the process. We can also provide feedback for people to become better forecasters. 

**Basic Path to Impact**

Looks like this

1. Better information about the future
2. Better decision
3. Better outcome

Metaculus is currently mainly focused on the first step which is essential. But these steps are related. That's why we put significantly more effort into cooperation with partners who focus on 2 and 3.

The relationship between informations, decisions and outcomes is where I see the biggest opportunities in the forecasting space. 